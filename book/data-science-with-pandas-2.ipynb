{
 "cells": [
  {
   "cell_type": "raw",
   "id": "14f401b8-2d1d-4a01-a3c8-ed2c59e66d29",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Data Science with Pandas (part 2: Grouping, Indexing, Slicing, and Subsetting DataFrames)\"\n",
    "format: html\n",
    "execute:   \n",
    "  enabled: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc321ea",
   "metadata": {},
   "source": [
    "## Recap: Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69d6058",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "surveys_df = pd.read_csv('../surveys.csv')\n",
    "surveys_df.describe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bf467b",
   "metadata": {},
   "source": [
    "We often want to calculate summary statistics grouped by subsets or attributes within fields of our data. For example, we might want to calculate the average weight of all individuals per site.\n",
    "\n",
    "For exampe we want to know how heavy our samples are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ca9007",
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys_df['plot_id'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0b4f74",
   "metadata": {},
   "source": [
    "We can also extract one specific metric if we wish:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfefa8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys_df['weight'].min()\n",
    "surveys_df['weight'].max()\n",
    "surveys_df['weight'].mean()\n",
    "surveys_df['weight'].std()\n",
    "surveys_df['weight'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf4b527",
   "metadata": {},
   "source": [
    "Now assume we want to get those statistics for the two groups \"male\" and \"female\".\n",
    "If we want to summarize data by one or more variables, we can use Pandas’ .groupby method. Once we’ve created a groupby DataFrame, we can quickly calculate summary statistics by a group of our choice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf8ba70-5aba-4c52-96e4-f4cda4c47268",
   "metadata": {},
   "source": [
    "## Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab6f950",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = surveys_df.groupby('sex')\n",
    "grouped_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09779445",
   "metadata": {},
   "source": [
    "The output is a bit overwhelming. Let's just have a look at one statistical value, the mean, to understand what is happening here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4344c205",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080e1045",
   "metadata": {},
   "source": [
    "We see that the data is divided into two groups, one group where the value in the column *sex* equals \"F\" and another group where the value in the column *sex* equals \"M\". The statistics is then calculated for all samples in that specific group for each of the columns in the dataframe. Note that samples annotated with sex equals NaN and column values with NaN are left out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbaa69a",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "Let's see in which plots animals get more food. Calculate the average weight per plot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2d241c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = surveys_df.groupby(...)\n",
    "grouped_data[...].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db66e63b",
   "metadata": {},
   "source": [
    "## Structure of a groupby object\n",
    "We can investigate which rows are assigned to which group as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a57600",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(grouped_data.groups)) # dictionary\n",
    "print(\"Plot ids: \", grouped_data.groups.keys()) # keys are the unique values of the column we grouped by\n",
    "print(\"Rows belonging to plot id \", 1, \": \", grouped_data.groups[1]) # values are row indexes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2d9af6",
   "metadata": {},
   "source": [
    "## Grouping by multiple columns\n",
    "Now let's have a look at a more complex grouping example. We want an overview statistics of the weight of all females and males by plot id. So in fact we want to group by *sex* and by *plot_id* at the same time.\n",
    "\n",
    "This will give us exactly 48 groups for our survey data:\n",
    "- female, plot id = 1\n",
    "- female, plot id = 2\n",
    "- ...\n",
    "- female, plot id = 24\n",
    "- male, plot id = 1\n",
    "- ...\n",
    "- male, plot id = 24\n",
    "\n",
    "Why 48 groups? We have 24 unique values for *plot_id*. Per plot we have two groups of samples, female and male. Hence, the grouping returns 48 groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e33e508",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = surveys_df.groupby(['sex', 'plot_id'])\n",
    "grouped_data[\"weight\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16879923",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "Investigate the group keys and row indexes for this more complex grouping example. \n",
    "Why are there more than 48 groups?\n",
    "What happened to the third group and why dos it not turn up in our statistics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40815c91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aef3af1c",
   "metadata": {},
   "source": [
    "## Counting and plotting\n",
    "Another very useful outcome of grouping is the possibility of performing selective counting. For example, let's see how to count the number of records per species. We just need to remember that each species has a unique ID and that records are identified by another ID stored in the column record ID. We will first group our data according to the species ID and then, for each group, we will count the number of records. Several consecutive operations that, once again, Pandas allows us to execute in a single line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14278e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "species_counts = surveys_df.groupby('species_id')['record_id'].count()\n",
    "print(type(grouped_species_counts))\n",
    "species_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf4ecba",
   "metadata": {
    "tags": []
   },
   "source": [
    "We can also plot the information for better overview. We will learn more about plotting after the next chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcb893b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "species_counts.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0028999f",
   "metadata": {},
   "source": [
    "## Summary grouping\n",
    "Grouping is one of the most common operation in data analysis. Data often consists of different measurements on the same sample. And in many cases we are not only interested in one particular measurement but in the cross product of measurements. In the picture below we labeled samples with green lines, blue dots and red lines. We are now interested how these three different groups relate to each other given the all other measurements in the dataframe.\n",
    "\n",
    "If we group a Pandas dataframe we in fact receive an object that contains three "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcaad2c1-a90f-43b1-9950-948209792458",
   "metadata": {
    "tags": []
   },
   "source": [
    "![Grouping sketch](pictures/grouping.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e561f37-84b5-4081-906c-ec23c48292c1",
   "metadata": {},
   "source": [
    "## Indexing, Slicing, and Subsetting DataFrames (I did not review this part CS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098b3e8a-059a-4c50-a8a0-dcaf2e0c450e",
   "metadata": {},
   "source": [
    "We saw that using grouping we can conveniently subset our DataFrame according to different measurement characteristics. However, sometimes it is necessary to \"surgically\" extract small portions of DataFrame such us single rows and columns of data satisfying very specific filtering criteria. In this paragraph we will see how Pandas allows to perform all these operations with a quite intuitive syntax."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e4a6ef-c56c-43d4-b12a-3de9177b63e2",
   "metadata": {},
   "source": [
    "### Selecting "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700abef7-b29b-491c-84e8-c26e0b2cce66",
   "metadata": {},
   "source": [
    "Let's look again at our original DataFrame columns using a loop. This time we will add some extra conditional statements to highlight the column name corresponding to a specific index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375a1d8a-d31f-4096-be5e-f514825d2b4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sel_index = 5\n",
    "print('Index) Column name')\n",
    "for i,col in enumerate(surveys_df.columns):\n",
    "    if i == sel_index:\n",
    "        print('{}) {} <==='.format(i,col))\n",
    "    else:\n",
    "        print('{}) {}'.format(i,col))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c0431e-a995-4f65-b6ac-57bcb581251c",
   "metadata": {},
   "source": [
    "We already saw in one of the previous paragraph how to extract a specific DataFrame column, but we did not go too much into details. The next block of code shows how to retrieve the same column (specied_id corresponding to index 5) from our DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7763b53-772e-456d-bffa-94945a9b8451",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#By name\n",
    "# --------------------------------------\n",
    "#Method1\n",
    "plot_id_1 = surveys_df['species_id']\n",
    "\n",
    "#Method2\n",
    "plot_id_2 = surveys_df.species_id\n",
    "# --------------------------------------\n",
    "\n",
    "#By location\n",
    "# --------------------------------------\n",
    "#Method3\n",
    "plot_id_3 = surveys_df[surveys_df.columns[5]]\n",
    "\n",
    "#Method4\n",
    "plot_id_4 = surveys_df.iloc[:,5]\n",
    "# --------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e851be-e8d5-4d43-b9d9-25e3be30ed76",
   "metadata": {},
   "source": [
    "In the first two methods we extract the column specifying its name. The third method is substantially identical to the first one as the 6th (index 5) element of the Series ```surveys_df.columns``` is species_id. The fourth method uses the method ```iloc``` to select *all* the rows of the 6th column. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4477ca6f-9c69-4c56-bf2b-1496f5a83374",
   "metadata": {},
   "source": [
    "### Selecting data by type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b0f370-e2d1-4093-9b74-e79a259a96ca",
   "metadata": {},
   "source": [
    "The attributes ```dtypes``` contains information about the data types contained in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54150e08-8379-4d68-80cf-e57968409c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e37d2e4-4525-4353-af3e-666a9748b80a",
   "metadata": {},
   "source": [
    "This information is not only important for our data analysis, but it also allows us to eventually select subset of data according to its type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18f7299-f186-4b1a-8fdc-b93b9c552821",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "surveys_df_float_sel = surveys_df.select_dtypes(include = ['float64'])\n",
    "print(type(surveys_df_float_sel))\n",
    "surveys_df_float_sel.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4627856c-5e04-4372-927b-89854a20694b",
   "metadata": {},
   "source": [
    "In the previous block of code we used a method, ```.select_dtypes()```, to select the DataFrame columns storing only float64 values (double-precision floating point numbers)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a38a00-8b97-416d-838f-8a28dc60c695",
   "metadata": {},
   "source": [
    "### Selecting by string in name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9fca28-8eff-4d55-9cee-24f09df89ec0",
   "metadata": {},
   "source": [
    "Another very convenient option to select data is specifying a string that must be contained in the column names. DataFrame column names are indicative (or at least, they should be) of the characteristics relative to measurements. All the columns containing a unique identifier, for example, may contain the suffix \"id\" while all the measurements relative to a specific body part (another example) will most probably contain that body part name as well. In this context, the Pandas method ```.filter(like=<str>)``` will allow to extract only those columns containing a certain string in their names. \n",
    "For example, let's extract all columns containing some sort of ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55d1d09-889e-44d7-aa35-3b1e6c14469e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(surveys_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f2e1b3-15ac-4e59-b278-db0566ec95cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "surveys_df_str_sel = surveys_df.filter(like='_id')\n",
    "print(type(surveys_df_str_sel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7315187-10d6-43bb-911a-41fca7c23521",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "surveys_df_str_sel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375ec2f0-194b-4c29-8659-a01f73001aa8",
   "metadata": {},
   "source": [
    "### Slicing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da74d298-973c-4837-a093-7d2366a4f1fc",
   "metadata": {},
   "source": [
    "DataFrame slicing allows you to extract a portion of a DataFrame based on conditions or indices and create a new DataFrame containing only the subset of data that you are interested in. In Pandas slicing can be perfomed using the methods ```loc``` and '''iloc''' for slicing via names and indices, respectively. To remember the difference between the two, just notice that the \"i\" in ```iloc``` stands for \"index\".\n",
    "Let's start slicing our initial DataFrame into a 3x4 sub-DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1de7cb1-904b-46c4-a558-af0a4e4f3ec1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "surveys_df.iloc[0:3,0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854610d1-479e-4437-bc1f-7515f60406fd",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>WARNING:</b> In Python integer indexing starts with 0 and, when slicing using a continous range of indices, data corresponding to the last index is NOT included.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1e81eb-21b6-403f-977e-ff97f43721f0",
   "metadata": {},
   "source": [
    "We can obtain the same result using ```loc```, but we need to specify a list with the first 4 column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c42807-22e8-4614-a180-0277af134872",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "surveys_df.loc[[0,1,2],['record_id','month','day','year']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e46128-2ef5-4148-8ee2-4cd4a17b3cc3",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>TRY IT YOURSELF:</b> Can you tell what happens when you execute the following commands?\n",
    "</div>\n",
    "\n",
    "- ```surveys_df[0:1]```;\n",
    "- ```surveys_df[:4]```;\n",
    "- ```surveys_df[:-1]```.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489dad2a-73e0-45b7-a91d-523c791d7bd8",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>TRY IT YOURSELF:</b> What happens when you call the following commands? How are the two commands different?\n",
    "</div>\n",
    "\n",
    "- ```surveys_df.iloc[0:4, 1:4]```;\n",
    "- ```surveys_df.loc[0:4, 1:4]```.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1d296c-693b-4565-bea7-3e68235efd32",
   "metadata": {},
   "source": [
    "### Subsetting Data according to user-defined criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81c8251-6e95-46d7-86d6-7c1bb9293bff",
   "metadata": {},
   "source": [
    "We can extract subsets of our DataFrame following the general syntax ```data_frame[<condition_on_data>]```. <condition_on_data> is a conditional statement on the DataFrame content itself. You may think at the conditional statement as a question or query you ask to your DataFrame. Here there are some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e56eae8-a974-4179-b954-b10069854b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the data collected in 2002?\n",
    "surveys_df[surveys_df.year == 2002]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334b573a-a94a-4b6d-86a5-fdec07ae6ced",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# What are the data NOT collected in 2002?\n",
    "surveys_df[surveys_df.year != 2002]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d8e29d-03ae-430a-9e9e-4956a4f59dbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# What are the data NOT collected in 2002? (different syntax)\n",
    "surveys_df[~(surveys_df.year == 2002)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02c8a66-3774-4add-9100-3f96762ad9a5",
   "metadata": {},
   "source": [
    "Our filtering conditions may be very specific, they can target different columns in the DataFrame, and they can be combined using the logical operator \"&\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbfed86-acd7-4c15-b4e2-d2b289802f22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# What are the data collected between 2000 and 2002 on female species?\n",
    "surveys_df[(surveys_df.year >= 2000) & (surveys_df.year <= 2002) & (surveys_df.sex == 'F')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60aa552-3dcb-4340-ba63-02fb8bcfa886",
   "metadata": {},
   "source": [
    "The method ```isin()``` allows to specify a range of \"permitted\" values for a certain column. Here it follows another example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1f055d-7737-45a9-83ff-12b66888a814",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "surveys_df[(surveys_df.year == 2000) & (surveys_df.sex == 'F') & (surveys_df.month.isin([1,3,4]))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a05df5-f24f-4a10-a392-854730f0cee4",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>TRY IT YOURSELF:</b> \n",
    "    <ol>\n",
    "    <li> Create a new DataFrame that only contains observations with sex values that are not female or male. Print the number of rows in this new DataFrame. Verify the result by comparing the number of rows in the new DataFrame with the number of rows in the surveys DataFrame where sex is null.</li>\n",
    "    <li>Create a new DataFrame that contains only observations that are of sex male or female and where weight values are greater than 0.</li>\n",
    "    </ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c72626b-e077-49f5-adf7-a84ce7ab952f",
   "metadata": {},
   "source": [
    "## DataFrame Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d008aac8-bce7-4fb6-9290-d564afc7f90b",
   "metadata": {},
   "source": [
    "A simple exploration of our DataFrame showed us that there are columns full of invalid values (NaN). One of the most important preliminary operations of data analysis is cleaning your data set, i.e. \"getting rid\" of non numerical values. Now that we mastered selecting, slicing, and subsetting, we can easily clean our DataFrame with few lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87583bff-06c8-4414-9dc7-eb1be7121f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are there any invalid values in the weight column?\n",
    "n_tot = len(surveys_df)\n",
    "n_null_weight = len(surveys_df[pd.isnull(surveys_df.weight)])\n",
    "n_pos_weight  = len(surveys_df[surveys_df.weight > 0])\n",
    "\n",
    "print('Total number of rows:',n_tot)\n",
    "print('Number of null weight rows:',n_null_weight)\n",
    "print('Number of positive weight rows:',n_pos_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2cc712-1406-4676-b3cd-e98481a0e701",
   "metadata": {},
   "source": [
    "As you can see, out of 35549 weight measurements, 3266 are not usable. The remaining 32283 values are positive, so usable, values. What happens if we compute the mean weight ignoring the fact that there are not numeric values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c436e91-4a89-47bb-9e21-5ad3852285e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ave_weight = surveys_df.weight.mean()\n",
    "print(ave_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd957cc-a21a-4c99-93af-5ccd26ad2260",
   "metadata": {},
   "source": [
    "A smooth run, without errors or warnings. As we said several times, Pandas is a library designed for data analysis and when performing data analysis it is very common to deal with not numeric values. In particular, the ```.mean()``` method has an argument called *skipna* that when set TRUE (default value, so we do not need to specify it) excludes NA/null values. This means that, in this case, Pandas simply ignores whatever it is not numeric and it performs computations only on numeric values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefe36d7-8b42-41a6-8169-c1ec5ee8d10e",
   "metadata": {},
   "source": [
    "If we are not happy with Pandas default behaviour, we can manually decide which value to assigni to NA/null values. One possible choice is setting them to zero. To do that, we just need to apply the method ```.fillna(<value>)```, where <value> is the number we want to substitute to the NA/null value (in our case, 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2fd01c-df32-48d0-83d9-188c41d0f471",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_weight1 = surveys_df.weight.fillna(0)\n",
    "cleaned_weight_ave1 = cleaned_weight1.mean()\n",
    "print(cleaned_weight_ave1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189aad29-aa01-4e21-ba14-98067e3a2678",
   "metadata": {},
   "source": [
    "You probably noticed that compared to our previous mean computation, the result it's pretty different. This is because the mean is now computed on a sample with many more zeros compared to the previous one and, as a result, the value of the computed mean is smaller.\n",
    "Conscious of this problem, we may now choose a more appropriate value to \"fill\" our NA/null values. How about we use the \"clean\" mean of our first computation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d10875-5528-4d78-86e4-86efaaa8f39c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cleaned_weight2 = surveys_df.weight.fillna(surveys_df.weight.mean())\n",
    "cleaned_weight_ave2 = cleaned_weight2.mean()\n",
    "print(cleaned_weight_ave2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e469696a-c8c5-4147-a34d-b514500f245a",
   "metadata": {},
   "source": [
    "This time we obtain exactly the same result of our first computation, this is because we substituted the NA/null values with a mean computed excluding the NA/null values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bf2b6d-6469-457b-b15e-5f785973bc05",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>TRY IT YOURSELF:</b> Compute the average weight of data after having cleaned the weight and the sex column.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
