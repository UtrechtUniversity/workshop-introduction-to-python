{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Reading and Exploring data\"\n",
    "execute:   \n",
    "  enabled: true\n",
    "  error: true\n",
    "  freeze: auto\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous chapters we started with the fundamentals of Python. Now we will continue with more practical examples of doing data analysis with Python using the Pandas library.\n",
    "\n",
    "## Libraries\n",
    "\n",
    "The power of Python (and many programming languages) is in the libraries.\n",
    "\n",
    "A library (aka package) is a collection of files (aka python scripts) that contains **functions** that can be used to perform specific tasks. A library may also contain data. The functions in a library are typically related and used for a specific purpose, e.g. there are libraries for plotting, handling audio data and machine learning and many many more. Some libraries are built into python, but most packages need to be installed before you can use it.\n",
    "\n",
    "Important to add: libraries are developed and maintained by other Python users. A popular library like Pandas has a large user base and the maintainers are supported by several funders, which makes it a reliable library that is updated very frequently. But this is not always the case, on the other side of the spectrum, a library can also be published once and not maintained at all.\n",
    "\n",
    "## Pandas\n",
    "The python library [**Pandas**](https://pandas.pydata.org/about/) is a popular open-source data analysis and data manipulation library for Python which was developed in 2008. The library has some similarities with R, mainly related to the DataFrame data type that is used to handle table like datasets.\n",
    "\n",
    "Pandas is widely used in data analyses and machine learning, as it provides powerful tools for data handling and manipulation. Furthermore, it integrates well with other Python libraries for data analysis, machine learning, and statistical analysis, such as NumPy, Scikit-Learn, and StatsModels. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this first chapter we will explore the main features of Pandas related to reading and exploring a dataset. In the following chapters we will go into finding, selecting and grouping data, merging datasets and visualization. \n",
    "\n",
    "For this purpose, we will be using data from the <a url=\"https://figshare.com/articles/dataset/Portal_Project_Teaching_Database/1314459\">Portal Project Teaching Database</a>: real world example of life-history, population, and ecological data and, occasionally, a small ad-hoc dataset to exaplain DataFrame operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start our journey into Pandas functionalities, there are some preliminary operations to run. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Pandas library is not a built-in library of python, it needs to be installed and loaded. Installations instructions for Pandas are in the the [setup instructions](installation-and-setup.qmd) for this course. Assuming you already installed it, let's start importing the Pandas library and checking our installed version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to just type `import pandas`, but we chose to give the library an 'alias': `pd`. The main reason is that we can now use functions from the library by typing `pd` instead of `pandas` (see the following line  `print(pd.__version__)`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to read the data files that we will be using, we need to specify the location of the files (also referred to as 'path'). It is best practice to specify the path relative to the main project folder, so, in order to properly read our dataset, it's important to check that we are working in the main project folder. In order to do that, we will load another library called 'os', containing all sort of tools to interact with our operating system. The function ```os.getcwd()```, returns the current working directory (cwd)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the current working directory ends with `<...>/workshop-introduction-to-python`, where `<...>` is whatever directory you chose to download and unzip the course material, you are in the right place.\n",
    "If not, use `os.chdir(<...>)` to change the working directory, where `<...>` is the full path of the `workshop-introductions-to-python` directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's store the relative path of our data into a variable and let's check if the data file actually exists using the function ```os.path.exists()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_file = '../course_materials/data/surveys.csv'\n",
    "print(os.path.exists(data_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the result is True, we are all set up to go!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The very first operation we will perform is loading our data into a Pandas **DataFrame** using ```pd.read_csv()```. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "surveys_df = pd.read_csv(data_file)\n",
    "\n",
    "print(type(data_file))\n",
    "print(type(surveys_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas can read quite a large variety of formats like the *comma-separated values* (CSV) and Excel file formats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes values in CSV files are separated using \";\" or tabs. The default separator Pandas expects is a comma, if it is different it is necessary to specify the separator in an argument, e.g.: `pd.read_csv(data_file, sep=\";\")`. The documentation of pandas provides a [full overview](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html) of the arguments you may use for this function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Jupyter Notebook or Jupyter Lab you can visualise the DataFrame simply by writing its name in a code cell and running the cell (in the same way you would display the value of any variable). Let's have a look at our just created DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "surveys_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the DataFrame we can finally understand what a DataFrame actually is: a 2-dimensional data structure storing different types of variables in columns. All rows in the DataFrame have a row index (starting from 0). The columns have names. The row indices and column names can be used to do operations on values in the column (we will go into this later). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see Jupyter only prints the first and last 5 rows separated by `...` . In this way the notebook remains clear and tidy (printing the whole DataFrame may result in a large table and a lot of scrolling to get to the next code cell).\n",
    "\n",
    "It is, however, enough for a quick exploration of how the dataset looks like in terms of columns names, values, and potential reading errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Exercise 1</b>\n",
    "    \n",
    "Now go to the Jupyter Dashboard in your internet browser and open the notebook `afternoon_exercises.ipynb` and do exercise 1.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.callout-note}\n",
    "As you can see in this exercise a DataFrame object comes with several methods that can be applied to the DataFrame. A method is similar to a function, but it can only be applied to the object it belongs to and has a different notation than a function.\n",
    "\n",
    "Compare the notation of the function `len`: `len(surveys_df)`  \n",
    "with the DataFrame specific method `shape`: `surveys_df.shape`\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will take a closer look into the actual values in the DataFrame. In order to do this it is helpful to have the column names at hand (easy for copy-pasting):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(surveys_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see this gives you more information than just the column names. It is also possible to just print the column names using a for loop (see [chapter 4](Introduction_to_python_4.ipynb)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for column in surveys_df.columns:\n",
    "    print(column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's select the column *weight* in our DataFrame and let's run some statistics on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "surveys_df['weight']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot the values in a histogram:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "surveys_df['weight'].plot(kind='hist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you notice how easy it was to obtain a summary plot of a column of our DataFrame? We can repeat the same for every column with a single line of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "surveys_df['hindfoot_length'].plot(kind='hist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also make quick scatterplots to explore the relation between two columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline # what this does will be discussed in the last chapter about visualization\n",
    "ax1 = surveys_df.plot(x='weight', y='hindfoot_length', kind='scatter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Exercise 2</b>\n",
    "    \n",
    "Now go to the Jupyter Dashboard in your internet browser and continue with exercise 2.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of running the methods above one by one, we can obtain a statistical summary using the method ```.describe()```. Let's get a statistical summary for the weight column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "surveys_df['weight'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many more methods that can be used. For a complete overview, check out the [documentation of Pandas](https://pandas.pydata.org/pandas-docs/stable/reference/frame.html).\n",
    "Some useful ones are the `unique` method to display all unique values in a certain column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys_df['species_id'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or ```.nunique()``` to return the number of unique elements in a column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(surveys_df['plot_id'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps we want to get some insight into the values for certain species or plots, in the next chapter we will go into [making groups and selections](data-science-with-pandas-2.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "ef4342b9cd1753b48d34a4dec30b358168f7f31d59fdf5ff32eb29bf3d04187b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
